{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "<style>\n",
    "    @media print{\n",
    "        body {\n",
    "            position:relative !important;\n",
    "        }\n",
    "        .celltag_new_page {\n",
    "            page-break-before: always !important;\n",
    "        }\n",
    "    }\n",
    "</style>\n",
    "# COMPSCI 371 Homework 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members: Brian Janger, Matthew Wang, Caleb Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AT"
    ]
   },
   "source": [
    "### Problem 0 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "## Part 1: Mathematics of Correlation and Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 1.1 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider term $j$ in the convolution $a *_- b$, which we call $(a *_- b)_j$:\n",
    "\n",
    "$(a*_-b)_j = \\sum\\limits_i a_ib_{j-i}$\n",
    "\n",
    "Now, let $k = j - i$ and consider term $j$ in the convolution $b *_- a$, which we call $(b *_- a)_j$:\n",
    "\n",
    "$(b*_-a)_j = \\sum\\limits_i b_ia_{j-i} = \\sum\\limits_k a_kb_{j-k} = (a*_-b)_j$\n",
    "\n",
    "We can see through the change of variables that the two terms of the sums are the same, so convolution is commutative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 1.2 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider term $j$ in the correlation $a *_+ b$ which we call $(a *_+ b)_j$:\n",
    "\n",
    "$(a*_+b)_j = \\sum\\limits_i a_ib_{j+i}$\n",
    "\n",
    "Let $k = j+i$ and consider term $j$ in the correlation $b *_+ a$, which we call $(b *_+ a)_j$:\n",
    "\n",
    "$(b*_+a)_j = \\sum\\limits_i b_ia_{j+i} = \\sum\\limits_k a_kb_{k-j} = \\sum\\limits_k a_kb_{(-j)+k} = (a*_+b)_{-j}$\n",
    "\n",
    "We can see that term $j$ in the correlation $b*_+a$ is the same as term $(-j)$ in the correlation $a*_+b$, so the sums are in reverse order of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "## Part 2: Coding Correlation and Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os import path as osp\n",
    "\n",
    "\n",
    "def retrieve(file_name, semester='fall22', course='371', homework=10):\n",
    "    if osp.exists(file_name):\n",
    "        print('Using previously downloaded file {}'.format(file_name))\n",
    "    else:\n",
    "        fmt = 'https://www2.cs.duke.edu/courses/{}/compsci{}/homework/{}/{}'\n",
    "        url = fmt.format(semester, course, homework, file_name)\n",
    "        urlretrieve(url, file_name)\n",
    "        print('Downloaded file {}'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously downloaded file oracle.py\n"
     ]
    }
   ],
   "source": [
    "retrieve('oracle.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [],
   "source": [
    "from oracle import oracle, show\n",
    "\n",
    "\n",
    "def test(function, a=[1, 2, 3, 4], b=[5, 6]):\n",
    "    for operator in ('correlate', 'convolve'):\n",
    "        for mode in ('full', 'same', 'valid'):\n",
    "            for f, g in ((a, b), (b, a)):\n",
    "                c = function(operator, f, g, mode)\n",
    "                show(operator, f, g, mode, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a, b): \n",
    "    p_sum = 0\n",
    "    for i in range(0, min(len(a), len(b))):\n",
    "        p_sum += a[i] * b[i]\n",
    "    return p_sum \n",
    "\n",
    "def flip(s):\n",
    "    return s[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_convolution(a, b):\n",
    "    #ell is shorter array, s is longer array \n",
    "    ell = a\n",
    "    s = b\n",
    "    if(len(a) < len(b)): \n",
    "        s = a\n",
    "        ell = b\n",
    "    \n",
    "    convolution = []\n",
    "    for i in range(0, len(ell) - len(s) + 1): \n",
    "        convolution.append(dot(ell[i: i+len(s)], flip(s)))\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 27, 38]\n",
      "[16, 27, 38]\n"
     ]
    }
   ],
   "source": [
    "a, b = [1, 2, 3, 4], [5, 6]\n",
    "print(valid_convolution(a, b))\n",
    "print(valid_convolution(b, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use valid_convolution() to determing whether short left padding or long left padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 90, 128, 166, 204, 178, 136]\n"
     ]
    }
   ],
   "source": [
    "#In short left padding, we add 1 zero to the front, two to the back, and run valid_convolution()\n",
    "a = [1,2,3,4,5,6,7]\n",
    "b = [8,9,10,11]\n",
    "\n",
    "a_padded = [0,1,2,3,4,5,6,7,0,0]\n",
    "print(valid_convolution(a_padded, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 52, 90, 128, 166, 204, 178]\n"
     ]
    }
   ],
   "source": [
    "#In long left padding, we add 2 zero to the front, one to the back, and run valid_convolution()\n",
    "a = [1,2,3,4,5,6,7]\n",
    "b = [8,9,10,11]\n",
    "\n",
    "a_padded = [0,0,1,2,3,4,5,6,7,0]\n",
    "print(valid_convolution(a_padded, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolve([1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11], same) = [25, 52, 90, 128, 166, 204, 178]\n"
     ]
    }
   ],
   "source": [
    "c = oracle('convolve', a, b, 'same')\n",
    "show('convolve', a, b, 'same', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results given in our oracle() function matches with the long left padding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(array, left, right): \n",
    "    copy = []\n",
    "    for i in array: \n",
    "        copy.append(i)\n",
    "    for i in range(0, left): \n",
    "        copy.insert(0, 0)\n",
    "    for i in range(0, right): \n",
    "        copy.append(0)\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def apply(operation, a, b, mode):\n",
    "    ell = a\n",
    "    s = b\n",
    "    if(len(a) < len(b)): \n",
    "        s = a\n",
    "        ell = b\n",
    "\n",
    "    if operation == 'convolve': \n",
    "        if mode == 'full': \n",
    "            ell_padded = pad(ell, math.ceil(len(s) / 2), math.floor(len(s) / 2))\n",
    "            return valid_convolution(ell_padded, s)\n",
    "        elif mode == 'same': \n",
    "            ell_padded = pad(ell, math.ceil((len(s) - 1) / 2), math.floor((len(s) - 1) / 2))\n",
    "            return valid_convolution(ell_padded, s)\n",
    "        elif mode == 'valid':\n",
    "            return valid_convolution(ell, s)  \n",
    "    elif operation == 'correlate': \n",
    "        if mode == 'same': \n",
    "            ell_padded = pad(ell, math.ceil((len(s) - 1) / 2), math.floor((len(s) - 1) / 2))\n",
    "            if(len(b) > len(a)): \n",
    "                return apply('convolve', s, flip(ell_padded), 'valid')\n",
    "            else: \n",
    "                return apply('convolve', ell_padded, flip(s), 'valid')\n",
    "            \n",
    "        return apply('convolve', a, flip(b), mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlate([1, 2, 3, 4], [5, 6], full) = [6, 17, 28, 39, 20]\n",
      "correlate([5, 6], [1, 2, 3, 4], full) = [20, 39, 28, 17, 6]\n",
      "correlate([1, 2, 3, 4], [5, 6], same) = [6, 17, 28, 39]\n",
      "correlate([5, 6], [1, 2, 3, 4], same) = [39, 28, 17, 6]\n",
      "correlate([1, 2, 3, 4], [5, 6], valid) = [17, 28, 39]\n",
      "correlate([5, 6], [1, 2, 3, 4], valid) = [39, 28, 17]\n",
      "convolve([1, 2, 3, 4], [5, 6], full) = [5, 16, 27, 38, 24]\n",
      "convolve([5, 6], [1, 2, 3, 4], full) = [5, 16, 27, 38, 24]\n",
      "convolve([1, 2, 3, 4], [5, 6], same) = [5, 16, 27, 38]\n",
      "convolve([5, 6], [1, 2, 3, 4], same) = [5, 16, 27, 38]\n",
      "convolve([1, 2, 3, 4], [5, 6], valid) = [16, 27, 38]\n",
      "convolve([5, 6], [1, 2, 3, 4], valid) = [16, 27, 38]\n"
     ]
    }
   ],
   "source": [
    "test(apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "## Part 3: Back-Propagation through a Convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 3.1 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AT"
    ]
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray*}\n",
    "c_0 &=& a_0 b_0 \\\\\n",
    "c_1 &=& a_0 b_1 + a_1 b_0 \\\\\n",
    "c_2 &=& a_0 b_2 + a_1 b_1 + a_2 b_0 \\\\\n",
    "c_3 &=& a_1 b_2 + a_2 b_1 + a_3 b_0 \\\\\n",
    "c_4 &=& a_2 b_2 + a_3 b_1 \\\\\n",
    "c_5 &=& a_3 b_2\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the prescribed example:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\alpha &=& (\\frac{\\partial \\ell}{\\partial a_0},\\frac{\\partial \\ell}{\\partial a_1}, \\frac{\\partial \\ell}{\\partial a_2}, \\frac{\\partial \\ell}{\\partial a_3}) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a_0} &=& \\frac{\\partial \\ell}{\\partial c_0}\\frac{\\partial c_0}{\\partial a_0} + \\frac{\\partial \\ell}{\\partial c_1}\\frac{\\partial c_1}{\\partial a_0} + \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial a_0} = \\gamma_0b_0 + \\gamma_1b_1 + \\gamma_2b_2 \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a_1} &=& \\frac{\\partial \\ell}{\\partial c_1}\\frac{\\partial c_1}{\\partial a_1} + \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial a_1} + \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial a_1} = \\gamma_1b_0 + \\gamma_2b_1 + \\gamma_3b_2 \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a_2} &=& \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial a_2} + \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial a_2} + \\frac{\\partial \\ell}{\\partial c_4}\\frac{\\partial c_4}{\\partial a_2} = \\gamma_2b_0 + \\gamma_3b_1 + \\gamma_4b_2 \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a_3} &=& \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial a_3} + \\frac{\\partial \\ell}{\\partial c_4}\\frac{\\partial c_4}{\\partial a_3} + \\frac{\\partial \\ell}{\\partial c_5}\\frac{\\partial c_5}{\\partial a_3} = \\gamma_3b_0 + \\gamma_4b_1 + \\gamma_5b_2 \\\\\n",
    "\\beta &=& (\\frac{\\partial \\ell}{\\partial b_0},\\frac{\\partial \\ell}{\\partial b_1}, \\frac{\\partial \\ell}{\\partial b_2}) \\\\ \n",
    "\\frac{\\partial \\ell}{\\partial b_0} &=& \\frac{\\partial \\ell}{\\partial c_0}\\frac{\\partial c_0}{\\partial b_0} + \\frac{\\partial \\ell}{\\partial c_1}\\frac{\\partial c_1}{\\partial b_0} + \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial b_0} + \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial b_0}  = \\gamma_0a_0 + \\gamma_1a_1 + \\gamma_2a_2 + \\gamma_3a_3\\\\\n",
    "\\frac{\\partial \\ell}{\\partial b_1} &=& \\frac{\\partial \\ell}{\\partial c_1}\\frac{\\partial c_1}{\\partial b_1} + \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial b_1} + \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial b_1} + \\frac{\\partial \\ell}{\\partial c_4}\\frac{\\partial c_4}{\\partial b_1}  = \\gamma_1a_0 + \\gamma_2a_1 + \\gamma_3a_2 + \\gamma_4a_3\\\\\n",
    "\\frac{\\partial \\ell}{\\partial b_2} &=& \\frac{\\partial \\ell}{\\partial c_2}\\frac{\\partial c_2}{\\partial b_2} + \\frac{\\partial \\ell}{\\partial c_3}\\frac{\\partial c_3}{\\partial b_2} + \\frac{\\partial \\ell}{\\partial c_4}\\frac{\\partial c_4}{\\partial b_2} + \\frac{\\partial \\ell}{\\partial c_5}\\frac{\\partial c_5}{\\partial b_2}  = \\gamma_2a_0 + \\gamma_3a_1 + \\gamma_4a_2 + \\gamma_5a_3\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Given the above expresssions, we can see that $\\alpha$ can be written as a valid correlation of $\\gamma$ and $b$ and $\\beta$ can be written as a valid correlation of $\\gamma$ and $a$. Thus:\n",
    "$\\alpha = \\gamma *_+^v b$ and $\\beta = \\gamma *_+^v a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "## Part 4: Network Back-Propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tiny network](https://courses.cs.duke.edu//fall22/compsci371/homework/10/tiny_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 4.1 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_1 = -4$, $z_1 = 0$, $a_2 = 7$, $z_2 = 7$, $\\hat{y} = 3$\n",
    "\n",
    "quadratic loss $= \\frac{1}{2}[h(x)-y]^2 = \\frac{1}{2}[3-5]^2 = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 4.2 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray*}\n",
    "g_{\\hat{y}} &=& \\hat{y} - y = 3 - 5 = -2 \\\\\n",
    "g_b &=& g_{\\hat{y}} \\cdot 1 = -2 \\\\\n",
    "g_{v_2} &=& g_{\\hat{y}}\\ z_2 = -2 \\cdot 7 = -14\\\\\n",
    "g_{v_1} &=& g_{\\hat{y}}\\ z_1 = -2 \\cdot 0 = 0\\\\\n",
    "g_{z_2} &=& g_{\\hat{y}}\\ v_2 = -2 \\cdot 1 = -2\\\\\n",
    "g_{z_1} &=& g_{\\hat{y}}\\ v_1 = -2 \\cdot 4 = -8\\\\\n",
    "g_{a_2} &=& g_{\\hat{y}}\\ v_2\\ \\sigma(a_2) = -2 \\cdot 1 \\cdot 1 = -2 \\\\\n",
    "g_{a_1} &=& g_{\\hat{y}}\\ v_1\\ \\sigma(a_1) = -2 \\cdot 4 \\cdot 0 = 0 \\\\\n",
    "g_{u_{23}} &=& g_{a_2}\\ x_3 = -2 \\cdot 2 = -4 \\\\\n",
    "g_{u_{22}} &=& g_{a_2}\\ x_2 = -2 \\cdot -2 = 4 \\\\\n",
    "g_{u_{21}} &=& g_{a_2}\\ x_1 = -2 \\cdot -3 = 6 \\\\\n",
    "g_{u_{13}} &=& g_{a_1}\\ x_3 = 0 \\cdot 2 = 0 \\\\\n",
    "g_{u_{12}} &=& g_{a_1}\\ x_2 = 0 \\cdot -2 = 0 \\\\\n",
    "g_{u_{11}} &=& g_{a_1}\\ x_1 = 0 \\cdot -3 = 0\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "source": [
    "Collecting the relevant entries in reverse order yields\n",
    "\n",
    "$$\n",
    "g_{\\mathbf{w}} = (0, 0, 0, 6, 4, -4, 0, -14, -2)\\;.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "## Part 5: MNIST Digit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously downloaded file mnist.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "file_name = 'mnist.pickle'\n",
    "retrieve(file_name)\n",
    "with open(file_name, 'rb') as file:\n",
    "    mnist = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [],
   "source": [
    "def print_result(h, d):\n",
    "    accuracy = {\n",
    "        'train': h.score(d['train']['x'], d['train']['y']) * 100,\n",
    "        'test': h.score(d['test']['x'], d['test']['y']) * 100\n",
    "    }\n",
    "    print('training accuracy: {:.2f} percent'.format(accuracy['train']))\n",
    "    print('test accuracy: {:.2f} percent'.format(accuracy['test']))\n",
    "    max_points = 20\n",
    "    p = (accuracy['test'] - 90.) / (96. - 90.) * max_points\n",
    "    p = min((max_points, max((0, p))))\n",
    "    p = round(p)\n",
    "    print('{} out of {} points'.format(p, max_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "\n",
    "def experiment(data, hidden_layer_sizes, max_iter, alpha,\n",
    "               learning_rate_init, verbose=False):\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        max_iter=max_iter,\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        learning_rate='constant',\n",
    "        solver='sgd',\n",
    "        random_state=1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        mlp.fit(data['train']['x'], data['train']['y'])\n",
    "    print_result(mlp, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 5.1 (Exam Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a blind classification were run, with a balanced MNIST dataset, the expected accuracy of the blind classifier would be 1 divided by the total number of classification groups, which in this case would be 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "AST"
    ]
   },
   "source": [
    "### Problem 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "AT"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68690960\n",
      "Iteration 2, loss = 0.21285632\n",
      "Iteration 3, loss = 0.13624568\n",
      "Iteration 4, loss = 0.09436123\n",
      "Iteration 5, loss = 0.06508058\n",
      "Iteration 6, loss = 0.04197691\n",
      "Iteration 7, loss = 0.02729570\n",
      "Iteration 8, loss = 0.02040278\n",
      "Iteration 9, loss = 0.01347171\n",
      "Iteration 10, loss = 0.01071940\n",
      "Iteration 11, loss = 0.00767475\n",
      "Iteration 12, loss = 0.00471607\n",
      "Iteration 13, loss = 0.00173934\n",
      "Iteration 14, loss = 0.00113444\n",
      "Iteration 15, loss = 0.00089434\n",
      "Iteration 16, loss = 0.00066942\n",
      "Iteration 17, loss = 0.00057737\n",
      "Iteration 18, loss = 0.00051437\n",
      "Iteration 19, loss = 0.00047284\n",
      "Iteration 20, loss = 0.00043520\n",
      "Iteration 21, loss = 0.00040647\n",
      "Iteration 22, loss = 0.00038114\n",
      "training accuracy: 100.00 percent\n",
      "test accuracy: 96.19 percent\n",
      "20 out of 20 points\n"
     ]
    }
   ],
   "source": [
    "experiment(\n",
    "    mnist,\n",
    "    hidden_layer_sizes=(100, 25),\n",
    "    max_iter=22,\n",
    "    alpha=1e-8,\n",
    "    learning_rate_init=0.15,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
